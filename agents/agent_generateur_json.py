#!/usr/bin/env python3
"""
Agent GÃ©nÃ©rateur JSON - VeilleNLI  
Lit les fichiers Markdown depuis Google Drive et gÃ©nÃ¨re data.json pour le site dynamique
"""

import os
import json
import re
from datetime import datetime
from typing import Dict, List, Tuple
from google.oauth2 import service_account
from googleapiclient.discovery import build

# Configuration
GOOGLE_CREDENTIALS = json.loads(os.environ.get('GOOGLE_DRIVE_CREDENTIALS'))
FOLDER_ID = os.environ.get('GOOGLE_DRIVE_FOLDER_ID')


def telecharger_fichiers_markdown() -> Dict[str, str]:
    """
    TÃ©lÃ©charge les fichiers .md depuis Google Drive
    Returns: Dict avec nom_fichier -> contenu_markdown
    """
    print("ğŸ“¥ Connexion Ã  Google Drive...")
    
    credentials = service_account.Credentials.from_service_account_info(
        GOOGLE_CREDENTIALS,
        scopes=['https://www.googleapis.com/auth/drive.readonly']
    )
    
    service = build('drive', 'v3', credentials=credentials)
    
    # Rechercher les fichiers de veille
    query = f"'{FOLDER_ID}' in parents and (name='VeilleIA.md' or name='VeilleNews.md')"
    results = service.files().list(q=query, fields="files(id, name)").execute()
    files = results.get('files', [])
    
    if not files:
        print("âš ï¸  Aucun fichier de veille trouvÃ© dans Google Drive")
        return {}
    
    fichiers_markdown = {}
    for file in files:
        content = service.files().get_media(fileId=file['id']).execute()
        contenu_decode = content.decode('utf-8')
        fichiers_markdown[file['name']] = contenu_decode
        print(f"   âœ“ {file['name']} tÃ©lÃ©chargÃ© ({len(contenu_decode)} caractÃ¨res)")
    
    return fichiers_markdown


def extraire_metadata(contenu_md: str) -> Dict[str, str]:
    """
    Extrait les mÃ©tadonnÃ©es du front matter YAML
    Returns: Dict avec agent, date, catÃ©gorie
    """
    metadata = {
        'agent': 'Agent Veille',
        'date': datetime.now().strftime('%Y-%m-%d'),
        'categorie': 'Veille'
    }
    
    # Chercher le front matter entre ---
    match = re.match(r'^---\n(.*?)\n---', contenu_md, re.DOTALL)
    if match:
        yaml_content = match.group(1)
        for ligne in yaml_content.split('\n'):
            if ':' in ligne:
                cle, valeur = ligne.split(':', 1)
                metadata[cle.strip()] = valeur.strip()
    
    return metadata


def extraire_titre_principal(contenu_md: str) -> Tuple[str, str]:
    """
    Extrait le titre principal (# niveau 1) et l'Ã©dition
    Returns: (titre, edition)
    """
    lignes = contenu_md.split('\n')
    titre = "Veille hebdomadaire"
    edition = ""
    
    for i, ligne in enumerate(lignes):
        # Chercher le titre de niveau 1
        if ligne.strip().startswith('# '):
            titre = ligne.strip()[2:].strip().replace('**', '')
            # L'Ã©dition est souvent sur la ligne suivante
            if i + 1 < len(lignes):
                ligne_suivante = lignes[i + 1].strip()
                if ligne_suivante.startswith('**Ã‰dition') or ligne_suivante.startswith('**Edition'):
                    edition = ligne_suivante.replace('**', '').strip()
            break
    
    return titre, edition


def extraire_introduction(contenu_md: str) -> str:
    """
    Extrait le paragraphe d'introduction
    Returns: texte de l'introduction
    """
    lignes = contenu_md.split('\n')
    introduction = ""
    capture = False
    
    for ligne in lignes:
        ligne_clean = ligne.strip()
        
        # Commencer aprÃ¨s "## Introduction" ou "## **Introduction**"
        if '## ' in ligne_clean and 'introduction' in ligne_clean.lower():
            capture = True
            continue
        
        # ArrÃªter Ã  la prochaine section ##
        if capture and ligne_clean.startswith('## '):
            break
        
        # Capturer le texte
        if capture and ligne_clean and not ligne_clean.startswith('---'):
            introduction += ligne_clean + " "
    
    return introduction.strip()


def parser_sujet(contenu_section: str, titre_section: str) -> Dict:
    """
    Parse une section complÃ¨te de sujet
    Returns: Dict avec titre, resume, points_de_vue, fiabilite, sources
    """
    sujet = {
        'titre': titre_section,
        'resume': '',
        'resume_court': '',
        'resume_complet': '',
        'points_de_vue': [],
        'fiabilite': [],
        'sources': [],
        'contenu_complet': contenu_section
    }
    
    lignes = contenu_section.split('\n')
    section_actuelle = None
    source_actuelle = None
    
    for ligne in lignes:
        ligne_clean = ligne.strip()
        
        # DÃ©tecter les sous-sections (###)
        if ligne_clean.startswith('### '):
            section_actuelle = ligne_clean[4:].strip().lower().replace('**', '').replace('*', '')
            source_actuelle = None
            continue
        
        # Section RÃ©sumÃ©
        if section_actuelle and 'rÃ©sumÃ©' in section_actuelle:
            if ligne_clean and not ligne_clean.startswith('#'):
                sujet['resume'] += ligne_clean + " "
        
        # Section Points de vue croisÃ©s
        elif section_actuelle and 'points de vue' in section_actuelle:
            # DÃ©tecter une nouvelle source (format **Source X â€“ Nom**)
            if ligne_clean.startswith('**Source') or ligne_clean.startswith('**MÃ©dia'):
                source_match = re.match(r'\*\*.*?â€“\s*(.*?)\*\*', ligne_clean)
                if source_match:
                    source_actuelle = {
                        'nom': source_match.group(1).strip(),
                        'texte': ''
                    }
                    sujet['points_de_vue'].append(source_actuelle)
            elif source_actuelle and ligne_clean and not ligne_clean.startswith('#'):
                source_actuelle['texte'] += ligne_clean + " "
        
        # Section FiabilitÃ© & signaux faibles
        elif section_actuelle and ('fiabilitÃ©' in section_actuelle or 'signaux' in section_actuelle):
            if ligne_clean.startswith('-') or ligne_clean.startswith('â€¢'):
                point = ligne_clean.lstrip('-â€¢').strip()
                if point:
                    sujet['fiabilite'].append(point)
        
        # Section Sources
        elif section_actuelle and 'sources' in section_actuelle:
            # Format attendu : "- Titre â€“ URL" ou "- Titre - URL"
            if ligne_clean.startswith('-') or ligne_clean.startswith('â€¢'):
                source_text = ligne_clean.lstrip('-â€¢').strip()
                # SÃ©parer titre et URL
                separateurs = [' â€“ ', ' - ', ' â€” ']
                for sep in separateurs:
                    if sep in source_text:
                        parts = source_text.split(sep, 1)
                        if len(parts) == 2:
                            titre_source = parts[0].strip()
                            url = parts[1].strip()
                            sujet['sources'].append({
                                'titre': titre_source,
                                'url': url
                            })
                        break
                else:
                    # Fallback : si c'est juste une URL
                    if source_text.startswith('http'):
                        sujet['sources'].append({
                            'titre': 'Source',
                            'url': source_text
                        })
    
    # GÃ©nÃ©rer rÃ©sumÃ© court (40 premiers mots)
    sujet['resume'] = sujet['resume'].strip()
    mots = sujet['resume'].split()
    if len(mots) > 40:
        sujet['resume_court'] = ' '.join(mots[:40]) + '...'
        sujet['resume_complet'] = sujet['resume']
    else:
        sujet['resume_court'] = sujet['resume']
        sujet['resume_complet'] = sujet['resume']
    
    # Nettoyer les points de vue
    for pv in sujet['points_de_vue']:
        pv['texte'] = pv['texte'].strip()
    
    return sujet


def parser_sections(contenu_md: str) -> Tuple[List[Dict], List[Dict]]:
    """
    Parse toutes les sections du Markdown
    Returns: (sujets_importants (6 premiers), sujets_secondaires (reste))
    """
    lignes = contenu_md.split('\n')
    sections = []
    section_actuelle = None
    capture = False
    
    # Sections Ã  exclure - LIGNE 236 CORRIGEE SANS APOSTROPHE
    exclusions = ["introduction", "table des matieres", "synthese finale", "fin de l edition", "fin de l edition"]
    
    for ligne in lignes:
        ligne_clean = ligne.strip()
        
        # DÃ©tecter les sections de niveau 2 (##)
        if ligne_clean.startswith('## '):
            titre = ligne_clean[3:].strip().replace('**', '')
            titre_lower = titre.lower()
            
            # VÃ©rifier si on doit exclure cette section
            if any(excl in titre_lower for excl in exclusions):
                # Sauvegarder la section prÃ©cÃ©dente avant d'exclure
                if section_actuelle and capture:
                    sections.append(section_actuelle)
                capture = False
                section_actuelle = None
                continue
            
            # Sauvegarder la section prÃ©cÃ©dente
            if section_actuelle and capture:
                sections.append(section_actuelle)
            
            # CrÃ©er une nouvelle section
            section_actuelle = {
                'titre': titre,
                'contenu': ''
            }
            capture = True
        
        # Ajouter le contenu Ã  la section actuelle
        elif section_actuelle and capture:
            section_actuelle['contenu'] += ligne + '\n'
    
    # Ajouter la derniÃ¨re section
    if section_actuelle and capture:
        sections.append(section_actuelle)
    
    # Parser chaque section en sujet structurÃ©
    sujets_structures = []
    for section in sections:
        sujet = parser_sujet(section['contenu'], section['titre'])
        sujets_structures.append(sujet)
    
    # SÃ©parer en importants (6 premiers) et secondaires (reste)
    sujets_importants = sujets_structures[:6] if len(sujets_structures) >= 6 else sujets_structures
    sujets_secondaires = sujets_structures[6:] if len(sujets_structures) > 6 else []
    
    return sujets_importants, sujets_secondaires


def extraire_points_cles(contenu_md: str) -> List[str]:
    """
    Extrait les points clÃ©s de la synthÃ¨se finale
    Returns: Liste de points clÃ©s (max 5)
    """
    points = []
    lignes = contenu_md.split('\n')
    capture = False
    
    for ligne in lignes:
        ligne_clean = ligne.strip()
        
        # DÃ©tecter la section "Points clÃ©s"
        if '### ' in ligne_clean and ('points clÃ©s' in ligne_clean.lower() or 'points cles' in ligne_clean.lower()):
            capture = True
            continue
        
        # ArrÃªter Ã  la prochaine sous-section ###
        if capture and ligne_clean.startswith('### '):
            break
        
        # Capturer les points (numÃ©rotÃ©s ou puces)
        if capture:
            # Format numÃ©rotÃ© : "1. ", "2. ", etc.
            match_numero = re.match(r'^\d+\.\s+(.+)$', ligne_clean)
            if match_numero:
                points.append(match_numero.group(1).strip())
            # Format puce : "- " ou "â€¢ "
            elif ligne_clean.startswith('-') or ligne_clean.startswith('â€¢'):
                point = ligne_clean.lstrip('-â€¢').strip()
                if point:
                    points.append(point)
    
    return points[:5]  # Maximum 5 points


def generer_icone_categorie(titre: str) -> str:
    """
    GÃ©nÃ¨re un emoji/icÃ´ne adaptÃ© Ã  la catÃ©gorie du sujet
    Returns: emoji string
    """
    titre_lower = titre.lower()
    
    # Mapping catÃ©gories -> icÃ´nes
    mappings = {
        'technolog': 'âš™ï¸',
        'modÃ¨le': 'ğŸ¤–',
        'llm': 'ğŸ¤–',
        'open source': 'ğŸ‡¨ğŸ‡³',
        'chine': 'ğŸ‡¨ğŸ‡³',
        'recherche': 'ğŸ”¬',
        'scientific': 'ğŸ”¬',
        'rÃ©gulation': 'âš–ï¸',
        'gouvernance': 'âš–ï¸',
        'europe': 'ğŸ‡ªğŸ‡º',
        'industrie': 'ğŸ’¼',
        'investissement': 'ğŸ’¼',
        'marchÃ©': 'ğŸ’¼',
        'cybersÃ©curitÃ©': 'ğŸ”’',
        'sÃ©curitÃ©': 'ğŸ”’',
        'risque': 'âš ï¸',
        'application': 'ğŸ’»',
        'usage': 'ğŸ’»',
        'hardware': 'ğŸ”§',
        'compute': 'ğŸ”§',
        'international': 'ğŸŒ',
        'gÃ©opolitique': 'ğŸŒ',
        'politique': 'ğŸ›ï¸',
        'Ã©conomie': 'ğŸ’°',
        'entreprise': 'ğŸ’¼',
        'technologie': 'ğŸ’»',
        'innovation': 'ğŸ’¡',
        'Ã©cologie': 'ğŸŒ±',
        'environnement': 'ğŸŒ±',
        'transition': 'â™»ï¸',
        'nantes': 'ğŸ“',
        'rÃ©gion': 'ğŸ“'
    }
    
    for mot_cle, icone in mappings.items():
        if mot_cle in titre_lower:
            return icone
    
    return 'ğŸ“„'  # IcÃ´ne par dÃ©faut


def traiter_fichier_markdown(nom_fichier: str, contenu_md: str) -> Dict:
    """
    Traite un fichier Markdown complet et retourne un objet structurÃ©
    Returns: Dict avec toutes les donnÃ©es extraites
    """
    print(f"\nğŸ“Š Traitement de {nom_fichier}...")
    
    # Extraction des mÃ©tadonnÃ©es
    metadata = extraire_metadata(contenu_md)
    print(f"   âœ“ MÃ©tadonnÃ©es: {metadata['agent']} - {metadata['date']}")
    
    # Extraction du titre et Ã©dition
    titre, edition = extraire_titre_principal(contenu_md)
    print(f"   âœ“ Titre: {titre}")
    if edition:
        print(f"   âœ“ Ã‰dition: {edition}")
    
    # Extraction de l'introduction
    introduction = extraire_introduction(contenu_md)
    print(f"   âœ“ Introduction: {len(introduction)} caractÃ¨res")
    
    # Parser les sections
    sujets_importants, sujets_secondaires = parser_sections(contenu_md)
    print(f"   âœ“ Sujets importants: {len(sujets_importants)}")
    print(f"   âœ“ Sujets secondaires: {len(sujets_secondaires)}")
    
    # Ajouter des icÃ´nes aux sujets
    for sujet in sujets_importants + sujets_secondaires:
        sujet['icone'] = generer_icone_categorie(sujet['titre'])
    
    # Extraire les points clÃ©s
    points_cles = extraire_points_cles(contenu_md)
    print(f"   âœ“ Points clÃ©s: {len(points_cles)}")
    
    return {
        'metadata': metadata,
        'titre': titre,
        'edition': edition,
        'introduction': introduction,
        'sujets_importants': sujets_importants,
        'sujets_secondaires': sujets_secondaires,
        'points_cles': points_cles,
        'date_generation': datetime.now().isoformat()
    }


def generer_data_json(fichiers_markdown: Dict[str, str]) -> Dict:
    """
    GÃ©nÃ¨re la structure JSON complÃ¨te pour le site web
    Returns: Dict avec toutes les donnÃ©es de veille structurÃ©es
    """
    print("\nğŸ”¨ GÃ©nÃ©ration de la structure JSON...")
    
    data = {
        'version': '2.0',
        'date_generation': datetime.now().isoformat(),
        'veilles': {}
    }
    
    # Traiter chaque fichier
    for nom_fichier, contenu_md in fichiers_markdown.items():
        # DÃ©terminer le type de veille (ia ou news)
        if 'IA' in nom_fichier or 'ia' in nom_fichier:
            cle = 'ia'
        elif 'News' in nom_fichier or 'news' in nom_fichier:
            cle = 'news'
        else:
            cle = nom_fichier.replace('.md', '').lower()
        
        data['veilles'][cle] = traiter_fichier_markdown(nom_fichier, contenu_md)
    
    print(f"\nâœ… Structure JSON gÃ©nÃ©rÃ©e avec succÃ¨s")
    print(f"   - Veilles traitÃ©es: {', '.join(data['veilles'].keys())}")
    
    return data


def sauvegarder_json(data: Dict, chemin: str = 'docs/data.json'):
    """
    Sauvegarde les donnÃ©es en JSON
    """
    print(f"\nğŸ’¾ Sauvegarde dans {chemin}...")
    
    # CrÃ©er le dossier docs si nÃ©cessaire
    os.makedirs(os.path.dirname(chemin), exist_ok=True)
    
    # Sauvegarder avec indentation pour lisibilitÃ©
    with open(chemin, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    taille = os.path.getsize(chemin)
    print(f"   âœ“ Fichier sauvegardÃ©: {taille} octets ({taille/1024:.1f} KB)")


def main():
    """Point d'entrÃ©e principal"""
    print("=" * 70)
    print("ğŸš€ Agent GÃ©nÃ©rateur JSON - VeilleNLI")
    print("=" * 70)
    print(f"â° ExÃ©cution: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
    
    try:
        # 1. TÃ©lÃ©charger les fichiers Markdown
        fichiers_markdown = telecharger_fichiers_markdown()
        
        if not fichiers_markdown:
            print("\nâŒ Aucun fichier Ã  traiter. ArrÃªt.")
            return 1
        
        # 2. GÃ©nÃ©rer la structure JSON
        data_json = generer_data_json(fichiers_markdown)
        
        # 3. Sauvegarder le fichier JSON
        sauvegarder_json(data_json, 'docs/data.json')
        
        print("\n" + "=" * 70)
        print("âœ… Agent GÃ©nÃ©rateur JSON terminÃ© avec succÃ¨s!")
        print("=" * 70)
        print(f"ğŸ“Š Statistiques:")
        for cle, veille in data_json['veilles'].items():
            print(f"   - {cle.upper()}: {len(veille['sujets_importants'])} sujets principaux, "
                  f"{len(veille['sujets_secondaires'])} secondaires")
        print(f"\nğŸŒ Fichier disponible: docs/data.json")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ ERREUR: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
