"""
Agent Deep Research IA
Mod√®le : OpenAI Extended Thinking (Deep Research)
R√¥le : Recherche approfondie sur actualit√©s IA/LLM ‚Üí Markdown structur√©
Budget estim√© : ~0.20-0.30‚Ç¨ par recherche
"""

import os
import sys
import traceback
from datetime import datetime, timedelta
from typing import Dict, Any
from openai import OpenAI


# ================================================================================
# CONFIGURATION
# ================================================================================

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')

# Mod√®le Extended Thinking pour Deep Research
MODEL_DEEP_RESEARCH = "o1-2024-12-17"  # Mod√®le optimis√© pour recherche approfondie

# Fichier de sortie
OUTPUT_MARKDOWN = "research_ia.md"

# Timeout (recherches longues)
REQUEST_TIMEOUT = 600  # 10 minutes


# ================================================================================
# PROMPT DEEP RESEARCH IA
# ================================================================================

def generer_prompt_deep_research() -> str:
    """
    G√©n√®re le prompt pour Deep Research IA
    
    Returns:
        Prompt optimis√© pour recherche approfondie
    """
    
    date_fin = datetime.now()
    date_debut = date_fin - timedelta(days=7)
    
    prompt = f"""Tu es un analyste expert en IA/LLM qui effectue une recherche approfondie sur les d√©veloppements r√©cents en intelligence artificielle.

OBJECTIF : Identifier et analyser les actualit√©s IA/LLM IMPORTANTES des 7 derniers jours.

P√âRIM√àTRE G√âOGRAPHIQUE :
- √âtats-Unis (OpenAI, Anthropic, Meta, Google)
- Europe (Mistral AI France, startups europ√©ennes)
- Asie (DeepSeek Chine, entreprises asiatiques)
- **FOCUS SP√âCIAL** : IA √† Nantes et en Bretagne (startups, √©cosyst√®me local, √©v√©nements)

SOURCES PRIORITAIRES - PRIVIL√âGIER LES SOURCES OFFICIELLES :
- **Blogs officiels** : OpenAI Blog, Anthropic Blog, Google AI Blog, Meta AI Blog
- **Publications √©diteurs** : Mistral AI, Hugging Face, Stability AI
- **Recherche acad√©mique** : ArXiv, Papers with Code, conf√©rences (NeurIPS, ICML)
- **Communiqu√©s officiels** : annonces produits, lev√©es de fonds
- **M√©dias tech de r√©f√©rence** : TechCrunch, The Verge, Wired, VentureBeat
- **√âviter** : agr√©gateurs secondaires, contenus marketing, republications

TH√àMES √Ä COUVRIR :
1. Nouveaux mod√®les LLM (GPT, Claude, Gemini, Llama, Mistral, DeepSeek)
2. Agents autonomes et Agentic AI
3. Multimodal AI (vision, audio, vid√©o)
4. Reasoning models (o1, o3, R1, chain-of-thought)
5. Open source et √©cosyst√®mes (Hugging Face, communaut√©)
6. Recherche scientifique (papers ArXiv, conf√©rences)
7. R√©gulation et gouvernance (AI Act Europe, l√©gislations)
8. Safety, Alignment, risques IA
9. Investissements et industrie (lev√©es de fonds, acquisitions)
10. Hardware IA (NVIDIA, AMD, TPU, Groq, puces sp√©cialis√©es)
11. **Startups fran√ßaises et europ√©ennes** (focus Mistral AI, Poolside, etc.)
12. **IA Nantes et Bretagne** : √©cosyst√®me local, startups, √©v√©nements, recherche

CRIT√àRES DE S√âLECTION :
- Actualit√© des 7 derniers jours PRIORITAIRE
- Accepter analyses/rapports r√©cents sur √©v√©nements plus anciens si tr√®s pertinents
- EXCLURE : contenu republi√©/recycl√©, annonces marketing mineures, tutoriels basiques
- PRIVIL√âGIER : vraies nouveaut√©s, annonces officielles, r√©sultats de recherche, sources primaires

P√âRIODE ANALYS√âE : du {date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}

FORMAT DE SORTIE MARKDOWN :

```markdown
# Recherche Deep - Veille IA
Date : {date_fin.strftime('%Y-%m-%d')}
P√©riode : {date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')}

## Articles identifi√©s

### [TITRE ARTICLE 1]
- **Source** : [Nom m√©dia ou blog officiel]
- **URL** : [URL compl√®te]
- **Date** : [Date publication estim√©e]
- **Th√®me** : [Th√®me principal parmi les 12 ci-dessus]
- **R√©sum√©** : [3-4 lignes synth√©tiques reformul√©es]
- **Pertinence** : [Score 1-10]
- **Tags** : [tag1, tag2, tag3]
- **Zone g√©o** : [USA/Europe/Asie/France/Nantes-Bretagne]

### [TITRE ARTICLE 2]
[...]

[R√©p√©ter pour TOUS les articles trouv√©s - viser 20-25 articles minimum]

## Statistiques de la recherche
- Nombre total d'articles : [X]
- P√©riode couverte : {date_debut.strftime('%d/%m/%Y')} √† {date_fin.strftime('%d/%m/%Y')}
- R√©partition th√©matique :
  - Nouveaux mod√®les : [X]
  - Agents : [X]
  - Multimodal : [X]
  - Reasoning : [X]
  - Open source : [X]
  - Recherche : [X]
  - R√©gulation : [X]
  - Safety : [X]
  - Investissements : [X]
  - Hardware : [X]
  - France/Europe : [X]
  - Nantes/Bretagne : [X]
- R√©partition g√©ographique :
  - USA : [X]
  - Europe : [X]
  - Asie : [X]
  - France : [X]
  - Nantes/Bretagne : [X]
- Sources utilis√©es : [Liste des principaux m√©dias/blogs]
```

CONSIGNES CRITIQUES :
- Vise 20-25 articles de haute qualit√© MINIMUM
- Reformule TOUS les r√©sum√©s (JAMAIS de copier-coller)
- URLs compl√®tes OBLIGATOIRES
- Score pertinence strict : 9-10 = exceptionnel, 7-8 = important, 5-6 = int√©ressant, <5 = √† filtrer
- Privil√©gie sources originales (blogs officiels OpenAI/Anthropic/Mistral, papers ArXiv, communiqu√©s)
- Pour Nantes/Bretagne : chercher startups locales, √©v√©nements IA, initiatives r√©gionales
- √âquilibre g√©ographique : 50% USA, 30% Europe, 15% Asie, 5% Nantes/Bretagne

Effectue ta recherche approfondie maintenant et g√©n√®re le Markdown complet.
"""
    
    return prompt


# ================================================================================
# DEEP RESEARCH AVEC OPENAI o1
# ================================================================================

def executer_deep_research() -> str:
    """
    Lance une recherche approfondie via OpenAI Extended Thinking
    
    Returns:
        Markdown structur√© avec articles trouv√©s
    """
    
    if not OPENAI_API_KEY:
        raise ValueError("‚ùå OPENAI_API_KEY manquante")
    
    print("ü§ñ Initialisation client OpenAI...")
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    prompt = generer_prompt_deep_research()
    
    print(f"üîç Lancement Deep Research (timeout {REQUEST_TIMEOUT}s)...")
    print("‚è≥ Cette recherche peut prendre 2-5 minutes...")
    
    try:
        response = client.chat.completions.create(
            model=MODEL_DEEP_RESEARCH,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            timeout=REQUEST_TIMEOUT
        )
        
        markdown_content = response.choices[0].message.content.strip()
        
        # Nettoyer les backticks markdown si pr√©sents
        if markdown_content.startswith('```markdown'):
            lines = markdown_content.split('\n')
            markdown_content = '\n'.join(lines[1:-1]) if len(lines) > 2 else markdown_content
            markdown_content = markdown_content.replace('```markdown', '').replace('```', '').strip()
        
        print(f"‚úÖ Recherche termin√©e")
        print(f"üìä Tokens utilis√©s : {response.usage.total_tokens}")
        
        # Estimation co√ªt (o1 est plus cher que GPT-4)
        # o1-2024-12-17 : ~$15/1M input tokens, ~$60/1M output tokens
        cost_input = (response.usage.prompt_tokens / 1_000_000) * 15
        cost_output = (response.usage.completion_tokens / 1_000_000) * 60
        cost_total = cost_input + cost_output
        
        print(f"üí∞ Co√ªt estim√© : ${cost_total:.4f}")
        print(f"üìù Markdown g√©n√©r√© : {len(markdown_content)} caract√®res")
        
        return markdown_content
    
    except Exception as e:
        print(f"‚ùå Erreur lors de la recherche : {e}")
        traceback.print_exc()
        raise


# ================================================================================
# SAUVEGARDE MARKDOWN
# ================================================================================

def sauvegarder_markdown(contenu: str, filepath: str) -> None:
    """
    Sauvegarde le Markdown g√©n√©r√©
    
    Args:
        contenu: Contenu Markdown
        filepath: Chemin du fichier
    """
    print(f"üíæ Sauvegarde dans {filepath}...")
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(contenu)
    
    file_size = os.path.getsize(filepath)
    print(f"‚úÖ Fichier sauvegard√© : {filepath}")
    print(f"üìä Taille : {file_size} octets ({file_size / 1024:.2f} KB)")


# ================================================================================
# MAIN
# ================================================================================

def main():
    """Point d'entr√©e principal"""
    
    try:
        print("=" * 80)
        print("üî¨ DEEP RESEARCH IA - OpenAI Extended Thinking")
        print("=" * 80)
        print(f"‚è∞ Ex√©cution : {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        print(f"üìÇ R√©pertoire : {os.getcwd()}")
        print()
        
        if not OPENAI_API_KEY:
            print("‚ùå ERREUR : OPENAI_API_KEY manquante")
            sys.exit(1)
        
        print("üîç √âTAPE 1/2 : Deep Research en cours...")
        print("-" * 80)
        markdown = executer_deep_research()
        print()
        
        print("üíæ √âTAPE 2/2 : Sauvegarde du r√©sultat")
        print("-" * 80)
        sauvegarder_markdown(markdown, OUTPUT_MARKDOWN)
        print()
        
        print("=" * 80)
        print("‚úÖ DEEP RESEARCH IA TERMIN√â")
        print("=" * 80)
        print(f"üìÑ Fichier : {OUTPUT_MARKDOWN}")
        print(f"üîó Pr√™t pour agent de mise en forme")
        print()
        
        sys.exit(0)
    
    except Exception as e:
        print("\n" + "=" * 80)
        print("‚ùå ERREUR FATALE")
        print("=" * 80)
        print(f"Type : {type(e).__name__}")
        print(f"Message : {e}")
        traceback.print_exc()
        print("=" * 80)
        sys.exit(1)


if __name__ == "__main__":
    main()
