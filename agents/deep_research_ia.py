"""
Agent de Veille IA avec Recherche Web
Mod√®le : GPT-5.2 avec web_search
R√¥le : Recherche web sur actualit√©s IA/LLM ‚Üí Analyse ‚Üí Synth√®se Markdown
Budget estim√© : ~0.10‚Ç¨ par ex√©cution
"""

import os
import sys
import traceback
from datetime import datetime, timedelta
from typing import Dict, Any
from openai import OpenAI


# ================================================================================
# CONFIGURATION
# ================================================================================

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')

# Mod√®le GPT-5.2 avec web search
MODEL_GPT52 = "gpt-5.2"

# Fichier de sortie
OUTPUT_MARKDOWN = "research_ia.md"

# Timeout (recherches longues)
REQUEST_TIMEOUT = 600  # 10 minutes

# Limite tokens de sortie
MAX_OUTPUT_TOKENS = 2000


# ================================================================================
# PROMPT RECHERCHE WEB IA
# ================================================================================

def generer_prompt_recherche() -> str:
    """
    G√©n√®re le prompt pour recherche web IA avec synth√®se
    
    Returns:
        Prompt optimis√© pour recherche web + analyse + synth√®se
    """
    
    date_fin = datetime.now()
    date_debut = date_fin - timedelta(days=7)
    
    prompt = f"""Tu es un analyste expert en IA/LLM. Ta mission comporte 3 √©tapes :

√âTAPE 1 : RECHERCHE WEB
Utilise l'outil de recherche web pour trouver des articles R√âELS et R√âCENTS sur l'IA/LLM.
N'invente JAMAIS d'URLs fictives.

√âTAPE 2 : ANALYSE
Analyse les articles trouv√©s pour identifier les plus pertinents.

√âTAPE 3 : SYNTH√àSE MARKDOWN
G√©n√®re un document Markdown structur√© avec les articles s√©lectionn√©s.

P√âRIM√àTRE G√âOGRAPHIQUE :
- √âtats-Unis (OpenAI, Anthropic, Meta, Google)
- Europe (Mistral AI France, startups europ√©ennes)
- Asie (DeepSeek Chine, entreprises asiatiques)
- **FOCUS SP√âCIAL** : IA √† Nantes et en Bretagne (startups, √©cosyst√®me local, √©v√©nements)

SOURCES PRIORITAIRES :
- **Blogs officiels** : OpenAI Blog, Anthropic Blog, Google AI Blog, Meta AI Blog
- **Publications √©diteurs** : Mistral AI, Hugging Face, Stability AI
- **Recherche acad√©mique** : ArXiv, Papers with Code, conf√©rences (NeurIPS, ICML)
- **Communiqu√©s officiels** : annonces produits, lev√©es de fonds
- **M√©dias tech** : TechCrunch, The Verge, Wired, VentureBeat
- **√âviter** : agr√©gateurs secondaires, contenus marketing, republications

TH√àMES √Ä COUVRIR :
1. Nouveaux mod√®les LLM (GPT, Claude, Gemini, Llama, Mistral, DeepSeek)
2. Agents autonomes et Agentic AI
3. Multimodal AI (vision, audio, vid√©o)
4. Reasoning models (o1, o3, R1, chain-of-thought)
5. Open source et √©cosyst√®mes (Hugging Face, communaut√©)
6. Recherche scientifique (papers ArXiv, conf√©rences)
7. R√©gulation et gouvernance (AI Act Europe, l√©gislations)
8. Safety, Alignment, risques IA
9. Investissements et industrie (lev√©es de fonds, acquisitions)
10. Hardware IA (NVIDIA, AMD, TPU, Groq, puces sp√©cialis√©es)
11. **Startups fran√ßaises et europ√©ennes** (focus Mistral AI, Poolside, etc.)
12. **IA Nantes et Bretagne** : √©cosyst√®me local, startups, √©v√©nements, recherche

STRAT√âGIE DE RECHERCHE :
1. Effectue 15-20 recherches web cibl√©es sur les th√®mes ci-dessus
2. Pour chaque th√®me, cherche "actualit√© [th√®me] derni√®re semaine"
3. V√©rifie la date de publication des articles trouv√©s
4. Priorise les sources officielles et les annonces r√©centes
5. Pour Nantes/Bretagne : "actualit√© IA Nantes", "startup IA Bretagne", etc.

CRIT√àRES DE S√âLECTION :
- Actualit√© des 7 derniers jours PRIORITAIRE
- Accepter analyses/rapports r√©cents sur √©v√©nements plus anciens si tr√®s pertinents
- EXCLURE : contenu republi√©/recycl√©, annonces marketing mineures, tutoriels basiques
- PRIVIL√âGIER : vraies nouveaut√©s, annonces officielles, r√©sultats de recherche, sources primaires
- **CRITICAL** : TOUTES les URLs DOIVENT √™tre R√âELLES (trouv√©es par web search)

P√âRIODE ANALYS√âE : du {date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}

FORMAT DE SORTIE MARKDOWN :

```markdown
# Veille IA - Recherche Web
Date : {date_fin.strftime('%Y-%m-%d')}
P√©riode : {date_debut.strftime('%d/%m/%Y')} - {date_fin.strftime('%d/%m/%Y')}

## Articles identifi√©s

### [TITRE ARTICLE 1]
- **Source** : [Nom m√©dia ou blog officiel]
- **URL** : [URL compl√®te R√âELLE trouv√©e via web search]
- **Date** : [Date publication R√âELLE]
- **Th√®me** : [Th√®me principal parmi les 12 ci-dessus]
- **R√©sum√©** : [3-4 lignes synth√©tiques reformul√©es]
- **Pertinence** : [Score 1-10]
- **Tags** : [tag1, tag2, tag3]
- **Zone g√©o** : [USA/Europe/Asie/France/Nantes-Bretagne]

### [TITRE ARTICLE 2]
[...]

[R√©p√©ter pour TOUS les articles trouv√©s - viser 15-20 articles minimum]

## Statistiques de la recherche
- Nombre total d'articles : [X]
- P√©riode couverte : {date_debut.strftime('%d/%m/%Y')} √† {date_fin.strftime('%d/%m/%Y')}
- Nombre de recherches web effectu√©es : [X]
- R√©partition th√©matique :
  - Nouveaux mod√®les : [X]
  - Agents : [X]
  - Multimodal : [X]
  - Reasoning : [X]
  - Open source : [X]
  - Recherche : [X]
  - R√©gulation : [X]
  - Safety : [X]
  - Investissements : [X]
  - Hardware : [X]
  - France/Europe : [X]
  - Nantes/Bretagne : [X]
- R√©partition g√©ographique :
  - USA : [X]
  - Europe : [X]
  - Asie : [X]
  - France : [X]
  - Nantes/Bretagne : [X]
- Sources utilis√©es : [Liste des principaux m√©dias/blogs]
```

CONSIGNES CRITIQUES :
- UTILISE LA RECHERCHE WEB pour CHAQUE th√®me important
- Vise 15-20 articles de haute qualit√© MINIMUM
- Reformule TOUS les r√©sum√©s (JAMAIS de copier-coller)
- **URLs compl√®tes R√âELLES OBLIGATOIRES** (trouv√©es via web search)
- **N'INVENTE JAMAIS d'URLs** - si tu n'as pas trouv√© d'article r√©cent, indique-le
- Score pertinence strict : 9-10 = exceptionnel, 7-8 = important, 5-6 = int√©ressant, <5 = √† filtrer
- Privil√©gie sources originales (blogs officiels OpenAI/Anthropic/Mistral, papers ArXiv, communiqu√©s)
- Pour Nantes/Bretagne : chercher startups locales, √©v√©nements IA, initiatives r√©gionales
- √âquilibre g√©ographique : 50% USA, 30% Europe, 15% Asie, 5% Nantes/Bretagne

Effectue maintenant :
1. RECHERCHE WEB (15-20 recherches)
2. ANALYSE des r√©sultats
3. SYNTH√àSE au format Markdown avec URLs R√âELLES
"""
    
    return prompt


# ================================================================================
# RECHERCHE WEB AVEC GPT-5.2
# ================================================================================

def executer_recherche_web() -> str:
    """
    Lance une recherche web via GPT-5.2, analyse et synth√©tise
    
    Returns:
        Markdown structur√© avec articles trouv√©s et URLs r√©elles
    """
    
    if not OPENAI_API_KEY:
        raise ValueError("‚ùå OPENAI_API_KEY manquante")
    
    print("ü§ñ Initialisation client OpenAI...")
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    prompt = generer_prompt_recherche()
    
    print(f"üîç Lancement recherche web GPT-5.2 (timeout {REQUEST_TIMEOUT}s)...")
    print("‚è≥ Cette recherche peut prendre 2-4 minutes...")
    print("üåê Web search activ√© pour URLs r√©elles")
    print("üìä √âtapes : Recherche ‚Üí Analyse ‚Üí Synth√®se")
    
    try:
        # API GPT-5.2 : client.responses.create()
        # SYNTAXE CORRIG√âE selon documentation OpenAI
        response = client.responses.create(
            model=MODEL_GPT52,
            input=prompt,
            max_output_tokens=MAX_OUTPUT_TOKENS,
            temperature=0.3,  # Au niveau racine, pas dans generation_config
            tools=[{"type": "web_search"}]  # Liste d'outils, pas dict
        )
        
        # R√©cup√©ration du contenu (GPT-5.2 format)
        markdown_content = response.output_text.strip()
        
        # Nettoyer les backticks markdown si pr√©sents
        if markdown_content.startswith('```markdown'):
            lines = markdown_content.split('\n')
            markdown_content = '\n'.join(lines[1:-1]) if len(lines) > 2 else markdown_content
            markdown_content = markdown_content.replace('```markdown', '').replace('```', '').strip()
        
        print(f"‚úÖ Recherche et synth√®se termin√©es")
        print(f"üìä Tokens g√©n√©r√©s : {response.usage.output_tokens}")
        print(f"üìù Markdown g√©n√©r√© : {len(markdown_content)} caract√®res")
        
        return markdown_content
    
    except Exception as e:
        print(f"‚ùå Erreur lors de la recherche : {e}")
        traceback.print_exc()
        raise


# ================================================================================
# SAUVEGARDE MARKDOWN
# ================================================================================

def sauvegarder_markdown(contenu: str, filepath: str) -> None:
    """
    Sauvegarde le Markdown g√©n√©r√©
    
    Args:
        contenu: Contenu Markdown
        filepath: Chemin du fichier
    """
    print(f"üíæ Sauvegarde dans {filepath}...")
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(contenu)
    
    file_size = os.path.getsize(filepath)
    print(f"‚úÖ Fichier sauvegard√© : {filepath}")
    print(f"üìä Taille : {file_size} octets ({file_size / 1024:.2f} KB)")


# ================================================================================
# MAIN
# ================================================================================

def main():
    """Point d'entr√©e principal"""
    
    try:
        print("=" * 80)
        print("üîç VEILLE IA - GPT-5.2 avec Recherche Web")
        print("=" * 80)
        print(f"‚è∞ Ex√©cution : {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        print(f"üìÇ R√©pertoire : {os.getcwd()}")
        print()
        
        if not OPENAI_API_KEY:
            print("‚ùå ERREUR : OPENAI_API_KEY manquante")
            sys.exit(1)
        
        print("üîç √âTAPE 1/2 : Recherche web + Analyse + Synth√®se")
        print("-" * 80)
        markdown = executer_recherche_web()
        print()
        
        print("üíæ √âTAPE 2/2 : Sauvegarde du r√©sultat")
        print("-" * 80)
        sauvegarder_markdown(markdown, OUTPUT_MARKDOWN)
        print()
        
        print("=" * 80)
        print("‚úÖ VEILLE IA TERMIN√âE")
        print("=" * 80)
        print(f"üìÑ Fichier : {OUTPUT_MARKDOWN}")
        print(f"üîó Pr√™t pour agent de mise en forme")
        print(f"‚úÖ URLs r√©elles v√©rifiables (GPT-5.2 web_search)")
        print()
        
        sys.exit(0)
    
    except Exception as e:
        print("\n" + "=" * 80)
        print("‚ùå ERREUR FATALE")
        print("=" * 80)
        print(f"Type : {type(e).__name__}")
        print(f"Message : {e}")
        traceback.print_exc()
        print("=" * 80)
        sys.exit(1)


if __name__ == "__main__":
    main()
