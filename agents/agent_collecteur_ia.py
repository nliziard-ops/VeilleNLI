"""
Agent 1 - Collecteur et Filtre IA
ModÃ¨le : GPT-4o-mini (Ã©conomique)
RÃ´le : Recherche web â†’ Filtrage â†’ Classification â†’ JSON
"""

import os
import sys
import json
import hashlib
import traceback
from datetime import datetime, timedelta
from typing import List, Dict, Any
from openai import OpenAI
import requests


# ================================================================================
# CONFIGURATION
# ================================================================================

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
TAVILY_API_KEY = os.environ.get('TAVILY_API_KEY')

# ModÃ¨le Ã©conomique pour filtrage
MODEL_COLLECTEUR = "gpt-4o-mini-2024-07-18"

# Fichier de sortie - utiliser le rÃ©pertoire courant pour GitHub Actions
OUTPUT_JSON = "articles_filtres_ia.json"


# ================================================================================
# TAVILY SEARCH
# ================================================================================

def recherche_tavily(query: str, max_results: int = 10) -> List[Dict[str, Any]]:
    """
    Effectue une recherche web via Tavily API
    
    Args:
        query: RequÃªte de recherche
        max_results: Nombre maximum de rÃ©sultats
        
    Returns:
        Liste d'articles avec titre, URL, snippet, date
    """
    if not TAVILY_API_KEY:
        print("âŒ TAVILY_API_KEY manquante")
        return []
    
    url = "https://api.tavily.com/search"
    
    payload = {
        "api_key": TAVILY_API_KEY,
        "query": query,
        "max_results": max_results,
        "search_depth": "basic",  # basic = rapide et Ã©conomique
        "include_answer": False,
        "include_raw_content": False,
        "include_images": False
    }
    
    try:
        response = requests.post(url, json=payload, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        resultats = []
        for item in data.get('results', []):
            resultats.append({
                'titre': item.get('title', ''),
                'url': item.get('url', ''),
                'snippet': item.get('content', ''),
                'score': item.get('score', 0.0)
            })
        
        return resultats
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ Erreur HTTP Tavily pour '{query}': {e}")
        return []
    except Exception as e:
        print(f"âŒ Erreur inattendue Tavily pour '{query}': {e}")
        traceback.print_exc()
        return []


# ================================================================================
# COLLECTE MULTI-REQUÃŠTES
# ================================================================================

def collecter_articles_bruts() -> List[Dict[str, Any]]:
    """
    Lance 12 recherches ciblÃ©es sur diffÃ©rents thÃ¨mes IA/LLM
    
    Returns:
        Liste brute d'articles (avec doublons potentiels)
    """
    
    # Calculer la pÃ©riode (7 derniers jours)
    date_fin = datetime.now()
    date_debut = date_fin - timedelta(days=7)
    
    # RequÃªtes ciblÃ©es pour maximiser la couverture
    requetes = [
        "AI LLM news this week",
        "OpenAI GPT latest announcements",
        "Anthropic Claude updates",
        "Google Gemini AI news",
        "Meta Llama open source",
        "AI regulation Europe 2026",
        "AI research papers this week",
        "AI cybersecurity threats",
        "enterprise AI applications",
        "AI hardware chips news",
        "AI France Nantes startup",
        "open source AI models"
    ]
    
    print(f"ğŸ” Lancement de {len(requetes)} recherches Tavily...")
    
    articles_bruts = []
    for i, query in enumerate(requetes, 1):
        print(f"  [{i}/{len(requetes)}] {query}")
        resultats = recherche_tavily(query, max_results=8)
        
        for res in resultats:
            articles_bruts.append({
                'titre': res['titre'],
                'url': res['url'],
                'snippet': res['snippet'],
                'score_tavily': res['score'],
                'requete_source': query
            })
    
    print(f"âœ… {len(articles_bruts)} articles bruts collectÃ©s")
    
    if len(articles_bruts) == 0:
        print("âš ï¸  Aucun article collectÃ© - vÃ©rifier la connexion Tavily")
    
    return articles_bruts


# ================================================================================
# FILTRAGE ET CLASSIFICATION GPT-4o-mini
# ================================================================================

def filtrer_et_classifier(articles_bruts: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Utilise GPT-4o-mini pour :
    - Supprimer doublons
    - Filtrer pertinence IA/LLM
    - Classifier par thÃ¨me
    - Attribuer score de pertinence
    
    Args:
        articles_bruts: Liste d'articles bruts
        
    Returns:
        Dictionnaire JSON structurÃ© prÃªt pour Agent 2
    """
    
    if len(articles_bruts) == 0:
        print("âš ï¸  Pas d'articles Ã  filtrer, crÃ©ation d'un JSON vide")
        date_fin = datetime.now()
        date_debut = date_fin - timedelta(days=7)
        return {
            "articles": [],
            "statistiques": {
                "articles_bruts": 0,
                "doublons_supprimes": 0,
                "articles_non_pertinents": 0,
                "articles_finaux": 0
            },
            "date_collecte": date_fin.strftime('%Y-%m-%d'),
            "periode": {
                "debut": date_debut.strftime('%Y-%m-%d'),
                "fin": date_fin.strftime('%Y-%m-%d')
            },
            "model_utilise": MODEL_COLLECTEUR,
            "themes": {}
        }
    
    print(f"ğŸ¤– CrÃ©ation client OpenAI...")
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # Calculer dates
    date_fin = datetime.now()
    date_debut = date_fin - timedelta(days=7)
    
    # PrÃ©parer les articles pour le prompt (limiter Ã  100 pour Ã©viter dÃ©passement tokens)
    articles_input = articles_bruts[:100]
    print(f"ğŸ“ PrÃ©paration de {len(articles_input)} articles pour GPT-4o-mini...")
    
    # CrÃ©er un texte compact pour GPT
    articles_text = "\n\n".join([
        f"[{i+1}] {art['titre']}\nURL: {art['url']}\nSnippet: {art['snippet'][:200]}..."
        for i, art in enumerate(articles_input)
    ])
    
    prompt = f"""Tu es un agent de filtrage et classification d'actualitÃ©s IA/LLM.

**PÃ‰RIODE ANALYSÃ‰E** : du {date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}

**ARTICLES BRUTS Ã€ ANALYSER** :
{articles_text}

**TA MISSION** :
1. Supprimer les doublons (mÃªme sujet, sources diffÃ©rentes â†’ garder la meilleure)
2. Filtrer uniquement les articles pertinents sur IA/LLM/GenAI
3. Exclure : annonces mineures, marketing produits, tutoriels basiques
4. Classifier chaque article dans UN thÃ¨me principal :
   - Nouveaux modÃ¨les LLM
   - Open source & Ã©cosystÃ¨mes
   - Recherche scientifique
   - RÃ©gulation & gouvernance
   - Industrie & investissements
   - CybersÃ©curitÃ© & risques
   - Applications entreprises
   - Hardware & compute
   - Europe & France
   - Nantes & RÃ©gion Ouest

5. Attribuer un score de pertinence (1-10) selon l'importance de l'actualitÃ©

**FORMAT DE SORTIE JSON** :
```json
{{
  "articles": [
    {{
      "titre": "Titre exact de l'article",
      "source": "Nom du mÃ©dia (ex: TechCrunch, Le Monde)",
      "url": "URL complÃ¨te",
      "date_estimee": "2026-01-10",
      "theme": "Nouveaux modÃ¨les LLM",
      "snippet": "RÃ©sumÃ© en 2-3 lignes des points clÃ©s",
      "pertinence": 9,
      "tags": ["GPT-5", "OpenAI", "benchmark"]
    }}
  ],
  "statistiques": {{
    "articles_bruts": {len(articles_bruts)},
    "doublons_supprimes": 0,
    "articles_non_pertinents": 0,
    "articles_finaux": 0
  }}
}}
```

**CONSIGNES** :
- Vise 12-18 articles finaux maximum (les plus importants)
- Reformule les snippets (pas de copier-coller)
- DÃ©tecte les doublons mÃªme avec titres lÃ©gÃ¨rement diffÃ©rents
- Sois strict sur la pertinence (ignorer le bruit mÃ©diatique)

GÃ©nÃ¨re le JSON maintenant :"""

    print("ğŸ¤– Appel API GPT-4o-mini pour filtrage...")
    
    try:
        response = client.chat.completions.create(
            model=MODEL_COLLECTEUR,
            messages=[
                {"role": "system", "content": "Tu es un agent de filtrage d'actualitÃ©s IA. Tu rÃ©ponds UNIQUEMENT en JSON valide, sans markdown, sans commentaires."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,  # Peu crÃ©atif, trÃ¨s factuel
            max_tokens=4000
        )
        
        # Extraire le JSON de la rÃ©ponse
        print(f"ğŸ“Š Tokens utilisÃ©s : {response.usage.total_tokens} (prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens})")
        
        json_text = response.choices[0].message.content.strip()
        
        # Nettoyer les backticks markdown si prÃ©sents
        if json_text.startswith('```'):
            lines = json_text.split('\n')
            json_text = '\n'.join(lines[1:-1]) if len(lines) > 2 else json_text
            json_text = json_text.replace('```json', '').replace('```', '').strip()
        
        print(f"ğŸ“ Parsing de la rÃ©ponse JSON ({len(json_text)} caractÃ¨res)...")
        
        # Parser le JSON
        data = json.loads(json_text)
        
        # Ajouter mÃ©tadonnÃ©es
        data['date_collecte'] = date_fin.strftime('%Y-%m-%d')
        data['periode'] = {
            'debut': date_debut.strftime('%Y-%m-%d'),
            'fin': date_fin.strftime('%Y-%m-%d')
        }
        data['model_utilise'] = MODEL_COLLECTEUR
        
        # GÃ©nÃ©rer IDs uniques pour chaque article
        for article in data['articles']:
            hash_input = f"{article['url']}{article['titre']}"
            article['id'] = hashlib.md5(hash_input.encode()).hexdigest()[:12]
        
        # Calculer statistiques thÃ©matiques
        themes_count = {}
        for article in data['articles']:
            theme = article['theme']
            themes_count[theme] = themes_count.get(theme, 0) + 1
        
        data['themes'] = themes_count
        data['statistiques']['articles_finaux'] = len(data['articles'])
        
        print(f"âœ… Filtrage terminÃ© : {len(data['articles'])} articles retenus")
        
        return data
    
    except json.JSONDecodeError as e:
        print(f"âŒ Erreur parsing JSON : {e}")
        print(f"RÃ©ponse brute (premiers 500 car) : {json_text[:500]}...")
        raise
    
    except Exception as e:
        print(f"âŒ Erreur GPT-4o-mini : {e}")
        traceback.print_exc()
        raise


# ================================================================================
# SAUVEGARDE JSON
# ================================================================================

def sauvegarder_json(data: Dict[str, Any], filepath: str) -> None:
    """
    Sauvegarde le JSON structurÃ©
    
    Args:
        data: DonnÃ©es Ã  sauvegarder
        filepath: Chemin du fichier
    """
    print(f"ğŸ’¾ Sauvegarde du JSON dans {filepath}...")
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    file_size = os.path.getsize(filepath)
    print(f"âœ… JSON sauvegardÃ© : {filepath}")
    print(f"ğŸ“Š Taille : {file_size} octets ({file_size / 1024:.2f} KB)")


# ================================================================================
# MAIN
# ================================================================================

def main():
    """Point d'entrÃ©e principal de l'agent collecteur"""
    
    try:
        print("=" * 80)
        print("ğŸ¤– AGENT 1 - COLLECTEUR IA (GPT-4o-mini)")
        print("=" * 80)
        print(f"â° ExÃ©cution : {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        print(f"ğŸ“‚ RÃ©pertoire de travail : {os.getcwd()}")
        print()
        
        # VÃ©rifier les clÃ©s API
        print("ğŸ”‘ VÃ©rification des clÃ©s API...")
        if not OPENAI_API_KEY:
            print("âŒ ERREUR CRITIQUE : OPENAI_API_KEY manquante")
            sys.exit(1)
        else:
            print(f"âœ… OPENAI_API_KEY prÃ©sente ({OPENAI_API_KEY[:10]}...)")
        
        if not TAVILY_API_KEY:
            print("âŒ ERREUR CRITIQUE : TAVILY_API_KEY manquante")
            sys.exit(1)
        else:
            print(f"âœ… TAVILY_API_KEY prÃ©sente ({TAVILY_API_KEY[:10]}...)")
        
        print()
        
        # Ã‰tape 1 : Collecte brute via Tavily
        print("ğŸ“¡ Ã‰TAPE 1/3 : Collecte d'articles via Tavily")
        print("-" * 80)
        articles_bruts = collecter_articles_bruts()
        print()
        
        # Ã‰tape 2 : Filtrage et classification via GPT-4o-mini
        print("ğŸ§¹ Ã‰TAPE 2/3 : Filtrage et classification (GPT-4o-mini)")
        print("-" * 80)
        data_filtree = filtrer_et_classifier(articles_bruts)
        print()
        
        # Ã‰tape 3 : Sauvegarde JSON
        print("ğŸ’¾ Ã‰TAPE 3/3 : Sauvegarde du JSON structurÃ©")
        print("-" * 80)
        sauvegarder_json(data_filtree, OUTPUT_JSON)
        print()
        
        # RÃ©sumÃ© final
        print("=" * 80)
        print("âœ… AGENT 1 TERMINÃ‰ AVEC SUCCÃˆS")
        print("=" * 80)
        print(f"ğŸ“Š Statistiques finales :")
        print(f"   - Articles bruts collectÃ©s : {data_filtree['statistiques']['articles_bruts']}")
        print(f"   - Articles aprÃ¨s filtrage : {data_filtree['statistiques']['articles_finaux']}")
        print(f"   - Doublons supprimÃ©s : {data_filtree['statistiques'].get('doublons_supprimes', 0)}")
        print()
        print(f"ğŸ“‚ Fichier JSON : {OUTPUT_JSON}")
        print(f"ğŸ”— PrÃªt pour Agent 2 (SynthÃ¨se)")
        print()
        
        sys.exit(0)
    
    except KeyboardInterrupt:
        print("\nâš ï¸  Interruption manuelle (Ctrl+C)")
        sys.exit(130)
    
    except Exception as e:
        print("\n" + "=" * 80)
        print("âŒ ERREUR FATALE")
        print("=" * 80)
        print(f"Type d'erreur : {type(e).__name__}")
        print(f"Message : {e}")
        print("\nTraceback complet :")
        traceback.print_exc()
        print("=" * 80)
        sys.exit(1)


if __name__ == "__main__":
    main()
