"""
Agent Recherche News v3 - Collecte PURE par recherche web libre
ModÃ¨le : GPT-5.2 (OpenAI Responses API)
StratÃ©gie : Recherche web gÃ©nÃ©rique sans sources imposÃ©es
RÃ´le : Collecte factuelle brute SANS tri, SANS analyse, SANS synthÃ¨se
Note : 26 articles pour permettre fusion/croisement par agent synthÃ¨se
"""

import os
import sys
import json
import hashlib
import traceback
from datetime import datetime, timedelta
from typing import Dict, Any
from openai import OpenAI

# Configuration
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
MODEL_RECHERCHE = "gpt-5.2"
OUTPUT_JSON = "recherche_news_brute.json"
MAX_ARTICLES = 26

def collecter_actualites_news() -> Dict[str, Any]:
    """
    Collecte les actualitÃ©s via recherche web libre.
    
    Returns:
        Dict avec articles, mÃ©tadonnÃ©es et statistiques
    """
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY manquant")
        return {"articles": [], "erreur": "API key manquante"}
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    date_fin = datetime.now()
    date_debut = date_fin - timedelta(days=7)
    
    # Prompt de collecte PURE - Recherche web libre sans sources imposÃ©es
    prompt = f"""Tu es un robot de collecte d'actualitÃ©s via web search - COLLECTE FACTUELLE PURE

MISSION:
Utilise la fonction web search pour trouver 26 articles d'actualitÃ© rÃ©cents publiÃ©s dans les 7 derniers jours ({date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}).

OBJECTIF: 26 articles
Pourquoi 26? L'agent de synthÃ¨se suivant pourra fusionner plusieurs articles (ex: 2 articles avec points de vue diffÃ©rents â†’ 1 article synthÃ©tique).
RÃ©sultat final visÃ©: ~6 articles synthÃ©tisÃ©s + ~20 articles liste.

RÃ‰PARTITION GÃ‰OGRAPHIQUE (flexible selon l'actualitÃ©):
- INTERNATIONAL: gÃ©opolitique, Ã©conomie mondiale, tech, climat, environnement
- NATIONAL FRANCE: politique, Ã©conomie, sociÃ©tÃ©, justice, culture
- LOCAL Bretagne/Nantes: 
  * ğŸŒŠ MER & VOILE: voile, courses nautiques, surf, kitesurf, wingfoil, sports maritimes
  * Ã‰conomie rÃ©gionale, ports, littoral, pÃªche
  * Politique locale, sociÃ©tÃ©, culture Bretagne

IMPORTANT - RÃ©partition flexible: 
La rÃ©partition International/National/Local dÃ©pend de l'actualitÃ© trouvÃ©e.
Pas de quota rigide, mais Ã©quilibre souhaitÃ©.

QUALITÃ‰ DES SOURCES:
âœ… PrivilÃ©gie: mÃ©dias reconnus, sources fiables, objectives, rÃ©putÃ©es
âœ… Diversifie: maximum 3 articles par source
âŒ Ã‰vite: blogs personnels, rÃ©seaux sociaux, sources partisanes/sensationnalistes

MÃ‰THODE DE RECHERCHE:
1. Fais des recherches web gÃ©nÃ©riques variÃ©es:
   - "actualitÃ©s internationales rÃ©centes fÃ©vrier 2026"
   - "actualitÃ©s France politique Ã©conomie fÃ©vrier 2026"
   - "actualitÃ©s Bretagne Nantes voile sports maritimes fÃ©vrier 2026"
   - "courses voile surf kitesurf actualitÃ©s fÃ©vrier 2026"
2. Collecte des articles de SOURCES DIFFÃ‰RENTES
3. VÃ©rifie que les articles sont RÃ‰CENTS (7 derniers jours)

CATÃ‰GORIES (choisis LA PLUS pertinente):
International: GÃ©opolitique | Ã‰conomie mondiale | Environnement & Climat | Tech
National: Politique nationale | Ã‰conomie France | SociÃ©tÃ© | Justice
Local: Mer & Voile | Sports maritimes | Ã‰conomie rÃ©gionale | Politique locale | Culture Bretagne

FORMAT JSON STRICT (sans markdown, sans commentaires):
{{
  "articles": [
    {{
      "titre": "Titre exact de l'article",
      "url": "https://source.com/article",
      "source": "Nom de la source",
      "date_publication": "YYYY-MM-DD",
      "contenu_brut": "RÃ©sumÃ© factuel 2-3 phrases du contenu",
      "zone_geo": "International OU National OU Local",
      "categorie_auto": "CatÃ©gorie pertinente"
    }}
  ],
  "periode": {{
    "debut": "{date_debut.strftime('%Y-%m-%d')}",
    "fin": "{date_fin.strftime('%Y-%m-%d')}"
  }},
  "nb_articles": 26,
  "repartition": {{"international": X, "national": Y, "local": Z}}
}}

CONSIGNES STRICTES:
- Retourner UNIQUEMENT le JSON (pas de texte avant/aprÃ¨s)
- 26 articles OBLIGATOIRE
- URLs complÃ¨tes et valides
- Dates au format YYYY-MM-DD
- Contenu factuel (pas d'opinion)
- Sources fiables et diversifiÃ©es
- Articles RÃ‰CENTS (7 derniers jours maximum)
- Pour LOCAL: ne pas oublier MER & VOILE (courses, sports nautiques)"""

    print(f"ğŸŒ Lancement GPT-5.2 + web search LIVE...")
    print(f"ğŸ“… Recherche : {date_debut.strftime('%d/%m')} - {date_fin.strftime('%d/%m')}")
    print(f"ğŸ¯ Objectif : {MAX_ARTICLES} articles (rÃ©partition flexible)")
    print(f"ğŸ† PrioritÃ© : sources fiables, diversifiÃ©es, objectives")
    print()
    
    try:
        response = client.responses.create(
            model=MODEL_RECHERCHE,
            tools=[{"type": "web_search", "external_web_access": True}],
            input=prompt
        )
        
        tokens_used = response.usage.total_tokens
        print(f"ğŸ“Š Tokens utilisÃ©s : {tokens_used}")
        
        # Nettoyage du JSON
        json_text = response.output_text.strip()
        if json_text.startswith('```'):
            lines = json_text.split('\n')
            json_text = '\n'.join(lines[1:-1]) if len(lines) > 2 else json_text
            json_text = json_text.replace('```json', '').replace('```', '').strip()
        
        # Parse JSON
        try:
            data = json.loads(json_text)
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur parsing JSON : {e}")
            print(f"ğŸ” RÃ©ponse brute (500 premiers chars):")
            print(response.output_text[:500])
            raise
        
        # Validation basique
        if 'articles' not in data:
            print(f"âš ï¸ ClÃ© 'articles' manquante. ClÃ©s prÃ©sentes: {list(data.keys())}")
            data['articles'] = []
        
        if not isinstance(data['articles'], list):
            print(f"âš ï¸ 'articles' n'est pas une liste. Type: {type(data['articles'])}")
            data['articles'] = []
        
        # Enrichissement mÃ©tadonnÃ©es
        data['date_collecte'] = date_fin.strftime('%Y-%m-%d %H:%M:%S')
        data['model_utilise'] = MODEL_RECHERCHE
        data['tokens_utilises'] = tokens_used
        data['agent'] = "Recherche News v3 - Web search libre"
        data['nb_articles'] = len(data.get('articles', []))
        
        # Calcul de la rÃ©partition rÃ©elle
        repartition = {'international': 0, 'national': 0, 'local': 0}
        categories = {}
        sources = {}
        
        for article in data.get('articles', []):
            # ID unique
            hash_input = f"{article.get('url', '')}{article.get('titre', '')}"
            article['id'] = hashlib.md5(hash_input.encode()).hexdigest()[:12]
            
            # RÃ©partition par zone
            zone = article.get('zone_geo', 'National')
            if zone == 'International':
                repartition['international'] += 1
            elif zone == 'Local':
                repartition['local'] += 1
            else:
                repartition['national'] += 1
            
            # RÃ©partition par catÃ©gorie
            cat = article.get('categorie_auto', 'Non classÃ©')
            categories[cat] = categories.get(cat, 0) + 1
            
            # Comptage des sources (diversitÃ©)
            source = article.get('source', 'Inconnue')
            sources[source] = sources.get(source, 0) + 1
        
        data['repartition'] = repartition
        
        nb_articles = data['nb_articles']
        print(f"\n{'âœ…' if nb_articles > 0 else 'âš ï¸'} {nb_articles} articles collectÃ©s")
        
        if nb_articles == 0:
            print("âŒ PROBLÃˆME: Aucun article collectÃ© !")
            print("ğŸ” VÃ©rifier si GPT-5.2 a accÃ¨s au web search")
        elif nb_articles < MAX_ARTICLES:
            print(f"âš ï¸ Attention : seulement {nb_articles}/{MAX_ARTICLES} articles")
        else:
            print(f"ğŸ“ RÃ©partition : {repartition['international']} Int | {repartition['national']} Nat | {repartition['local']} Local")
            
            print(f"ğŸ“Š RÃ©partition par catÃ©gorie (top 5) :")
            for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"   â€¢ {cat}: {count}")
            
            print(f"ğŸ¢ DiversitÃ© des sources : {len(sources)} sources diffÃ©rentes")
            sources_multiples = {s: c for s, c in sources.items() if c > 3}
            if sources_multiples:
                print(f"âš ï¸ Sources avec >3 articles : {sources_multiples}")
        
        return data
    
    except json.JSONDecodeError as e:
        print(f"âŒ Erreur JSON : {e}")
        print(f"ğŸ” RÃ©ponse brute complÃ¨te :")
        print(response.output_text)
        traceback.print_exc()
        raise
    
    except Exception as e:
        print(f"âŒ Erreur : {e}")
        traceback.print_exc()
        raise

def main():
    try:
        print("=" * 80)
        print("ğŸ¤– AGENT RECHERCHE NEWS v3 - WEB SEARCH LIBRE")
        print("=" * 80)
        print(f"ğŸ“… PÃ©riode : 7 derniers jours")
        print(f"ğŸ¯ Objectif : {MAX_ARTICLES} articles (fusion possible par synthÃ¨se)")
        print(f"ğŸŒ ModÃ¨le : {MODEL_RECHERCHE} + web search live")
        print(f"ğŸ† StratÃ©gie : sources fiables, diversifiÃ©es, objectives")
        print()
        
        data = collecter_actualites_news()
        
        # Sauvegarde JSON
        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print()
        print(f"âœ… Fichier gÃ©nÃ©rÃ© : {OUTPUT_JSON}")
        print(f"ğŸ“Š {data['nb_articles']} articles â€¢ {data['tokens_utilises']} tokens")
        
        print("=" * 80)
        
        # Exit code selon le nombre d'articles
        if data['nb_articles'] == 0:
            print("âš ï¸ WARNING: Aucun article collectÃ©, mais pas d'erreur bloquante")
            sys.exit(0)  # Ne pas bloquer le workflow
        else:
            sys.exit(0)
    
    except Exception as e:
        print()
        print(f"âŒ Ã‰CHEC : {e}")
        print("=" * 80)
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
