"""
Agent Recherche News v3 - COLLECTE PURE
Mod√®le : GPT-5.2 (OpenAI Responses API)
R√¥le : Collecte factuelle BRUTE avec web search LIVE
Max tokens : 10000
"""

import os
import sys
import json
import hashlib
import traceback
from datetime import datetime, timedelta
from typing import Dict, Any, List
from openai import OpenAI

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
MODEL_RECHERCHE = "gpt-5.2"
MAX_TOKENS = 10000
OUTPUT_JSON = "recherche_news_brute.json"

SOURCES_NEWS = [
    "Le Grand Continent", "El Pais", "BBC News", "Reuters",
    "Le Figaro", "Le Monde", "Monde Diplomatique",
    "Ouest-France", "Le T√©l√©gramme de Brest"
]


def rechercher_actualites_news() -> Dict[str, Any]:
    """
    Collecte BRUTE des actualit√©s g√©n√©rales sans tri ni analyse.
    Retourne JSON brut avec tous les articles trouv√©s (max 25).
    Distribution : 35% International, 35% France, 30% Local Bretagne.
    """
    if not OPENAI_API_KEY:
        print("‚ùå OPENAI_API_KEY manquant")
        return {"articles": [], "error": "No API key"}
    
    client = OpenAI(api_key=OPENAI_API_KEY)
    date_fin = datetime.now()
    date_debut = date_fin - timedelta(days=7)
    
    # PROMPT DE COLLECTE PURE - AUCUNE ANALYSE
    prompt = f"""Tu es un collecteur d'information. Ta SEULE mission : collecter des actualit√©s g√©n√©rales.

P√âRIODE : {date_debut.strftime('%d/%m/%Y')} au {date_fin.strftime('%d/%m/%Y')}

SOURCES PRIORITAIRES :
{', '.join(SOURCES_NEWS)}

DISTRIBUTION G√âOGRAPHIQUE CIBLE :
- 35% International (g√©opolitique, √©conomie mondiale, environnement global)
- 35% France (politique nationale, √©conomie France, soci√©t√© fran√ßaise)
- 30% Local Bretagne/Pays de Loire (Nantes, Brest, Belle-√éle, sports maritimes)

CONSIGNES STRICTES :
1. Collecte 20-25 actualit√©s maximum
2. NE FAIS AUCUN TRI
3. NE FAIS AUCUNE ANALYSE
4. NE FAIS AUCUNE SYNTH√àSE
5. Retourne UNIQUEMENT les informations brutes trouv√©es

CAT√âGORIES POSSIBLES :
International : G√©opolitique, √âconomie mondiale, Environnement global, Conflits
National : Politique fran√ßaise, √âconomie France, Soci√©t√©, √âducation, Sant√©
Local : Politique locale, √âconomie r√©gionale, Sports maritimes (voile, surf, kitesurf, wingfoil), Mer & littoral, Culture Bretagne

ZONES G√âOGRAPHIQUES :
- International
- National (France)
- Local (Bretagne/Pays de Loire)

FORMAT JSON STRICT (sans markdown) :
{{
  "articles": [
    {{
      "titre": "Titre exact de l'article",
      "url": "https://url-complete.com/article",
      "source": "Nom de la source",
      "date_publication": "YYYY-MM-DD",
      "zone_geo": "International ou National ou Local",
      "categorie": "Cat√©gorie parmi la liste ci-dessus",
      "contenu_brut": "R√©sum√© factuel complet de l'article tel que trouv√© (5-10 lignes)"
    }}
  ],
  "periode": {{
    "debut": "{date_debut.strftime('%Y-%m-%d')}",
    "fin": "{date_fin.strftime('%Y-%m-%d')}"
  }},
  "repartition_cible": {{
    "international": 35,
    "national": 35,
    "local": 30
  }},
  "sources_consultees": ["liste", "des", "sources"]
}}

FOCUS LOCAL : Actualit√©s de Nantes, Brest, Belle-√éle-en-Mer, sports de glisse maritime (voile, surf, kitesurf, wingfoil), √©v√©nements maritimes et littoraux.

IMPORTANT : R√©ponds UNIQUEMENT en JSON valide, sans ```json ni aucun markdown.
"""

    print("=" * 80)
    print("üîç COLLECTE BRUTE - GPT-5.2 + WEB SEARCH LIVE")
    print(f"üìÖ P√©riode : {date_debut.strftime('%d/%m/%Y')} ‚Üí {date_fin.strftime('%d/%m/%Y')}")
    print(f"üéØ Max tokens : {MAX_TOKENS}")
    print(f"üåç Distribution : 35% Int | 35% Nat | 30% Local")
    print("=" * 80)
    
    try:
        # SYNTAXE OFFICIELLE OPENAI - Responses API avec web search LIVE
        response = client.responses.create(
            model=MODEL_RECHERCHE,
            tools=[{"type": "web_search", "external_web_access": True}],
            input=prompt,
            max_tokens=MAX_TOKENS
        )
        
        print(f"üìä Tokens utilis√©s : {response.usage.total_tokens}/{MAX_TOKENS}")
        
        # Nettoyage du JSON (au cas o√π il y aurait du markdown)
        json_text = response.output_text.strip()
        if json_text.startswith('```'):
            lines = json_text.split('\n')
            json_text = '\n'.join(lines[1:-1]) if len(lines) > 2 else json_text
            json_text = json_text.replace('```json', '').replace('```', '').strip()
        
        # Parse JSON
        data = json.loads(json_text)
        
        # Ajout m√©tadonn√©es
        data['date_collecte'] = date_fin.strftime('%Y-%m-%d')
        data['model_utilise'] = MODEL_RECHERCHE
        data['agent'] = "Recherche News v3 (collecte pure)"
        data['max_tokens'] = MAX_TOKENS
        data['tokens_utilises'] = response.usage.total_tokens
        
        # Calcul r√©partition r√©elle
        if 'repartition_reelle' not in data:
            data['repartition_reelle'] = {'international': 0, 'national': 0, 'local': 0}
        
        # G√©n√©ration ID unique + comptage zones
        articles = data.get('articles', [])
        for article in articles:
            hash_input = f"{article.get('url', '')}{article.get('titre', '')}"
            article['id'] = hashlib.md5(hash_input.encode()).hexdigest()[:12]
            
            zone = article.get('zone_geo', 'National')
            if zone == 'International':
                data['repartition_reelle']['international'] += 1
            elif zone == 'Local':
                data['repartition_reelle']['local'] += 1
            else:
                data['repartition_reelle']['national'] += 1
        
        nb_articles = len(articles)
        print(f"‚úÖ {nb_articles} articles collect√©s")
        print(f"üìä R√©partition : Int={data['repartition_reelle']['international']} | "
              f"Nat={data['repartition_reelle']['national']} | "
              f"Local={data['repartition_reelle']['local']}")
        
        if nb_articles == 0:
            print("‚ö†Ô∏è  ATTENTION : Aucun article collect√©")
        elif nb_articles > 25:
            print(f"‚ö†Ô∏è  ATTENTION : {nb_articles} articles (limite 25 d√©pass√©e)")
        
        return data
    
    except json.JSONDecodeError as e:
        print(f"‚ùå Erreur parsing JSON : {e}")
        print(f"R√©ponse brute : {response.output_text[:500]}...")
        traceback.print_exc()
        raise
    
    except Exception as e:
        print(f"‚ùå Erreur collecte : {e}")
        traceback.print_exc()
        raise


def main():
    """Point d'entr√©e principal"""
    try:
        print("\n" + "=" * 80)
        print("ü§ñ AGENT RECHERCHE NEWS v3 - COLLECTE PURE")
        print("=" * 80 + "\n")
        
        # Collecte
        data = rechercher_actualites_news()
        
        # Sauvegarde JSON
        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ Fichier sauvegard√© : {OUTPUT_JSON}")
        print(f"üì¶ Taille : {os.path.getsize(OUTPUT_JSON)} octets")
        
        print("\n" + "=" * 80)
        print("‚úÖ COLLECTE TERMIN√âE")
        print("=" * 80 + "\n")
        
        sys.exit(0)
    
    except Exception as e:
        print(f"\n‚ùå ERREUR FATALE : {e}\n")
        sys.exit(1)


if __name__ == "__main__":
    main()
